# AnÃ¡lise ExploratÃ³ria de Dados LogÃ­sticos - Loggi (Distrito Federal)

Este projeto realiza uma anÃ¡lise exploratÃ³ria e um processo completo de **Data Wrangling** sobre dados logÃ­sticos da startup Loggi, com foco nas operaÃ§Ãµes no Distrito Federal (DF).

A anÃ¡lise utiliza dados geoespaciais para cruzar informaÃ§Ãµes de entregas com dados demogrÃ¡ficos (populaÃ§Ã£o, densidade urbana) das RegiÃµes Administrativas (RAs) do DF. O objetivo Ã© avaliar a eficiÃªncia da infraestrutura de distribuiÃ§Ã£o existente, considerando a alta variaÃ§Ã£o na densidade demogrÃ¡fica entre as trÃªs regiÃµes atendidas (DF-0, DF-1 e DF-2).

## ðŸŽ¯ Contexto e Objetivos

O principal objetivo Ã© analisar os dados de entrega da Loggi no Distrito Federal para avaliar a eficiÃªncia da infraestrutura de distribuiÃ§Ã£o. A anÃ¡lise foca em responder Ã s seguintes questÃµes de negÃ³cio:

1.  **A quantidade de HUBs de distribuiÃ§Ã£o estÃ¡ subdimensionada?**
2.  **A distribuiÃ§Ã£o de entregas por HUB estÃ¡ equilibrada?**

## ðŸ“‚ Fontes de Dados

Para esta anÃ¡lise, foram utilizadas as seguintes fontes de dados:

* `deliveries.json`: Arquivo JSON contendo dados brutos das entregas, incluindo informaÃ§Ãµes aninhadas sobre a origem (HUB) e os pontos de entrega.
* `distrito-federal.shp`: Shapefile com os limites geogrÃ¡ficos do Distrito Federal.
* `bairros-df.shp` / `bairros-df.shx`: Shapefiles com os polÃ­gonos das RegiÃµes Administrativas (RAs) do DF.
* `dimRA.xlsx`: Planilha Excel com dados demogrÃ¡ficos e de Ã¡rea das RegiÃµes Administrativas (PopulaÃ§Ã£o, Densidade Urbana, etc.).

## ðŸ› ï¸ Tecnologias e Bibliotecas

O projeto foi desenvolvido em Python, utilizando as seguintes bibliotecas principais:

* **Pandas:** Para manipulaÃ§Ã£o e anÃ¡lise de dados tabulares.
* **GeoPandas:** Para manipulaÃ§Ã£o e anÃ¡lise de dados geoespaciais.
* **Matplotlib** & **Seaborn:** Para visualizaÃ§Ã£o de dados (grÃ¡ficos e mapas).
* **Tabula-py** & **PyPDF2:** Para extraÃ§Ã£o de dados de arquivos PDF (conforme listado na instalaÃ§Ã£o).
* **Google Colab:** Como ambiente de desenvolvimento da anÃ¡lise.

## ðŸ“ˆ Metodologia da AnÃ¡lise

O projeto foi estruturado nas seguintes etapas:

1.  **Carregamento dos Dados:** Leitura do arquivo principal `deliveries.json`.
2.  **Data Wrangling (Limpeza e TransformaÃ§Ã£o):**
    * Desaninhamento (flattening) dos dados JSON das colunas `origin` (HUBs) e `deliveries` (entregas).
    * UtilizaÃ§Ã£o do mÃ©todo `pd.json_normalize` para a coluna `origin`.
    * UtilizaÃ§Ã£o do mÃ©todo `explode` para expandir a lista de entregas, criando uma linha por entrega.
    * ExtraÃ§Ã£o de informaÃ§Ãµes detalhadas de cada entrega (tamanho, ID, lat/lng).
    * JunÃ§Ã£o (merge) dos dados transformados em um DataFrame limpo e estruturado.
3.  **AnÃ¡lise ExploratÃ³ria (EDA):**
    * VerificaÃ§Ã£o de tipos de dados, valores nulos e valores Ãºnicos.
    * AnÃ¡lise estatÃ­stica descritiva das variÃ¡veis (ex: `delivery_size`, `vehicle_capacity`).
4.  **ManipulaÃ§Ã£o Geoespacial:**
    * Carregamento dos shapefiles do DF e das RegiÃµes Administrativas (RAs) com GeoPandas.
    * Carregamento dos dados demogrÃ¡ficos das RAs via arquivo Excel.
    * CriaÃ§Ã£o de GeoDataFrames para os HUBs e para os pontos de entrega a partir de suas coordenadas (lat/lng).
    * JunÃ§Ã£o geoespacial (`gpd.sjoin`) para identificar a qual RA pertence cada entrega.
5.  **VisualizaÃ§Ã£o e Insights:**
    * CriaÃ§Ã£o de mapas para visualizar a distribuiÃ§Ã£o dos HUBs e das entregas por regiÃ£o (DF-0, DF-1, DF-2).
    * Plotagem de um grÃ¡fico de barras com a proporÃ§Ã£o de entregas por HUB.
    * CriaÃ§Ã£o de um mapa coroplÃ©tico (choropleth map) da Densidade Urbana das RAs vs. a localizaÃ§Ã£o dos HUBs.

## ðŸ’¡ Principais Insights e ConclusÃµes

A anÃ¡lise dos dados permitiu extrair as seguintes observaÃ§Ãµes operacionais:

* **DesequilÃ­brio na DistribuiÃ§Ã£o:** Existe um claro desequilÃ­brio na carga de entregas. O **HUB DF-1** concentra a maior proporÃ§Ã£o de entregas (aprox. 48%), seguido pelo **DF-2** (aprox. 34%) e pelo **DF-0** (aprox. 18%).
* **EficiÃªncia Operacional e Custos:** O HUB DF-1 opera em uma regiÃ£o geogrÃ¡fica muito mais concentrada. Em contraste, os HUBs DF-0 e DF-2 cobrem Ã¡reas muito maiores e mais dispersas, sugerindo custos operacionais (como combustÃ­vel e tempo) significativamente mais altos para atender suas respectivas regiÃµes.
* **Oportunidades de OtimizaÃ§Ã£o (HUB DF-0):** O HUB DF-0 estÃ¡ visivelmente subutilizado. HÃ¡ um potencial de explorar melhor as RegiÃµes Administrativas de alta densidade urbana que estÃ£o em sua Ã¡rea de cobertura, como BrazlÃ¢ndia (ID 4) e ItapoÃ£ (ID 28).
* **Posicionamento EstratÃ©gico dos HUBs:** O mapa de densidade urbana revela que os HUBs poderiam estar melhor posicionados. Em particular, o **HUB DF-0** estÃ¡ localizado longe de Ã¡reas de alta densidade. Um reposicionamento mais ao sul, prÃ³ximo a ParanoÃ¡ (ID 7), poderia otimizar as rotas e reduzir custos operacionais.

## ðŸš€ Como Executar o Projeto

1.  **Acessar o Google Colab:**
    * Acesse [colab.research.google.com](https://colab.research.google.com).

2.  **Abrir o Notebook:**
    * FaÃ§a o upload do arquivo `.ipynb` do projeto para o Colab (Arquivo > Upload notebook...).
    * Se o repositÃ³rio estiver no GitHub, vocÃª pode abri-lo diretamente (Arquivo > Abrir notebook > GitHub > [Colar URL do repositÃ³rio] > Selecionar o notebook).

3.  **Carregar os Dados:**
    * FaÃ§a o upload dos arquivos de dados (`.json`, `.shp`, `.shx`, `.xlsx`, etc.) para o ambiente do Colab. VocÃª pode fazer isso manualmente pela aba "Arquivos" Ã  esquerda ou montar seu Google Drive.
    * *Nota: Lembre-se de ajustar os caminhos dos arquivos no cÃ³digo (`pd.read_json`, `gpd.read_file`, etc.) para corresponder ao local onde vocÃª carregou os dados no Colab (ex: `/content/deliveries.json`).*

4.  **Instalar DependÃªncias:**
    * O Google Colab jÃ¡ vem com `pandas`, `matplotlib` e `seaborn` prÃ©-instalados. VocÃª precisarÃ¡ instalar o `geopandas` e outras bibliotecas especÃ­ficas. Execute a seguinte cÃ©lula no inÃ­cio do notebook:
    ```python
    !pip install geopandas tabula-py PyPDF2
    ```

5.  **Executar a AnÃ¡lise:**
    * Com as dependÃªncias instaladas e os dados carregados, execute as cÃ©lulas do notebook (Ambiente de execuÃ§Ã£o > Executar tudo).
